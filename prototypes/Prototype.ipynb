{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#http://www.ritchieng.com/machine-learning/deep-learning/tensorflow/deep-neural-nets/\n",
    "#http://ischlag.github.io/2016/06/04/how-to-use-tensorboard/\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.set_random_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', -1)\n",
    "pd.set_option('precision', 18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "es = pd.read_csv(\"../vectors/es.node2vec.embeddings\", delimiter = \" \", skiprows = 1, header = None)\n",
    "na = pd.read_csv(\"../vectors/na.node2vec.embeddings\", delimiter = \" \", skiprows = 1, header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "es.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "na.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "es_vectores = np.array(es[:1900].loc[:,1::]).astype(np.float32)\n",
    "na_vectores = np.array(na[:1900].loc[:,1::]).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "es_vectores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "na_vectores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "es_palabras = es[0]\n",
    "na_palabras = na[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"shape es:\",es_vectores.shape,\"\\nshape na:\",na_vectores.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "LEARNING_RATE = 0.1\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 100\n",
    "\n",
    "NODES_INPUT = es_vectores[0].size\n",
    "NODES_H1 = 100\n",
    "NODES_H2 = 100\n",
    "NODES_OUPUT = na_vectores[0].size\n",
    "INSTANCES = es_vectores.__len__()\n",
    "NUM_STEPS = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"inputs\"):\n",
    "    X = tf.placeholder(shape=[None,NODES_INPUT], dtype=tf.float32,name='X')\n",
    "    y = tf.placeholder(shape=[None,NODES_OUPUT], dtype=tf.float32,name='y')\n",
    "    print(\"X:\",X.shape,\"y:\",y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Capas ocultas (weights & bias)\n",
    "with tf.name_scope(\"hidden_layer1\"):\n",
    "    hidden_layer1 = {\"W1\":tf.Variable(tf.truncated_normal([NODES_INPUT,NODES_H1],stddev=0.01),name = 'W1'),\n",
    "                 \"b1\":tf.constant(0.1,shape=[NODES_H1], name = 'b1')}\n",
    "with tf.name_scope(\"hidden_layer2\"):\n",
    "    hidden_layer2 = {\"W2\":tf.Variable(tf.truncated_normal([NODES_H1,NODES_H2],stddev=0.01),name = 'W2'),\n",
    "                     \"b2\":tf.constant(0.1,shape=[NODES_H2], name = 'b2')}\n",
    "\n",
    "# Capa de salida\n",
    "with tf.name_scope(\"output_layer1\"):\n",
    "    output_layer = {\"W2\":tf.Variable(tf.truncated_normal([NODES_H1,NODES_OUPUT],stddev=0.01),name = 'W_output'),\n",
    "                    \"b2\":tf.constant(0.1,shape=[NODES_OUPUT], name = 'b_output')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(hidden_layer1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calcular la salida de la 1er capa oculta\n",
    "# h(x) = x*w + bias\n",
    "hidden_layer1_output = tf.add(tf.matmul(es_vectores, hidden_layer1[\"W1\"]), hidden_layer1[\"b1\"],name=\"hidden1\")\n",
    "tf.summary.scalar('pre_activations1', hidden_layer1_output)\n",
    "# Función de activación usando ReLU\n",
    "with tf.name_scope(\"relu_layer1\"):\n",
    "    hidden_layer1_output = tf.nn.relu(hidden_layer1_output,name=\"actfhidden1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calcular la salida de la 2da capa oculta\n",
    "# h(x) = x*w + bias\n",
    "hidden_layer2_output = tf.add(tf.matmul(hidden_layer1_output, hidden_layer2[\"W2\"]), hidden_layer2[\"b2\"],name=\"hidden2\")\n",
    "tf.summary.scalar('pre_activations2', hidden_layer2_output)\n",
    "# Función de activación usando ReLU\n",
    "with tf.name_scope(\"relu_layer2\"):\n",
    "    hidden_layer2_output = tf.nn.relu(hidden_layer2_output,name=\"actfhidden2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calcular la salida la NN\n",
    "output = tf.add(tf.matmul(hidden_layer2_output, output_layer[\"W2\"]),output_layer[\"b2\"],name=\"output\")\n",
    "# Función de activación usando softmax\n",
    "with tf.name_scope(\"softmax\"):\n",
    "    nah_predicted = tf.nn.softmax(output,name=\"actfoutput\")\n",
    "print(nah_predicted.shape,y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Función de error (Mean Square Error)\n",
    "#loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels = y, logits = nah_predicted))\n",
    "with tf.name_scope(\"loss\"):\n",
    "    loss = tf.reduce_mean(tf.squared_difference(nah_predicted,y),name=\"loss_f\")\n",
    "#loss = tf.reduce_sum((nah_predicted - y) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# optimiser, \n",
    "with tf.name_scope(\"optimiser\"):\n",
    "    optimiser = tf.train.GradientDescentOptimizer(learning_rate = LEARNING_RATE,name=\"GradientDescent\").minimize(loss,name=\"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.summary.scalar(\"loss\",loss)\n",
    "summary_op = tf.summary.merge_all()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Session\n",
    "sess = tf.Session()\n",
    "# Initialize variables\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "#writer = tf.summary.FileWriter(\"./logs/NN\",sess.graph)\n",
    "writer = tf.summary.FileWriter(\"./logs/NN\", sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmp_hidden_layer1,tmp_hidden_layer2 = sess.run(hidden_layer1),sess.run(hidden_layer2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for step in range(3000):\n",
    "    '''\n",
    "    offset = (step * BATCH_SIZE) % (es_vectores.shape[0] - BATCH_SIZE)\n",
    "    batch_data = es_vectores[offset:(offset + BATCH_SIZE), :]\n",
    "    batch_target = na_vectores[offset:(offset + BATCH_SIZE), :]\n",
    "    '''\n",
    "    _, _loss = sess.run([optimiser,loss],feed_dict={X:es_vectores,y:na_vectores})\n",
    "    \n",
    "    if (step % 100) == 0:\n",
    "        print(_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(sess.run(hidden_layer1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "tmp_hidden_layer1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.run(hidden_layer2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# reset everything to rerun in jupyter\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# config\n",
    "batch_size = 100\n",
    "learning_rate = 0.5\n",
    "training_epochs = 5\n",
    "logs_path = \"/tmp/mnist/2\"\n",
    "\n",
    "# load mnist data set\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n",
    "\n",
    "# input images\n",
    "with tf.name_scope('input'):\n",
    "    # None -> batch size can be any size, 784 -> flattened mnist image\n",
    "    x = tf.placeholder(tf.float32, shape=[None, 784], name=\"x-input\") \n",
    "    # target 10 output classes\n",
    "    y_ = tf.placeholder(tf.float32, shape=[None, 10], name=\"y-input\")\n",
    "\n",
    "# model parameters will change during training so we use tf.Variable\n",
    "with tf.name_scope(\"weights\"):\n",
    "    W = tf.Variable(tf.zeros([784, 10]))\n",
    "\n",
    "# bias\n",
    "with tf.name_scope(\"biases\"):\n",
    "    b = tf.Variable(tf.zeros([10]))\n",
    "\n",
    "# implement model\n",
    "with tf.name_scope(\"softmax\"):\n",
    "    # y is our prediction\n",
    "    y = tf.nn.softmax(tf.matmul(x,W) + b)\n",
    "\n",
    "# specify cost function\n",
    "with tf.name_scope('cross_entropy'):\n",
    "    # this is our cost\n",
    "    cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices=[1]))\n",
    "\n",
    "# specify optimizer\n",
    "with tf.name_scope('train'):\n",
    "    # optimizer is an \"operation\" which we can execute in a session\n",
    "    train_op = tf.train.GradientDescentOptimizer(learning_rate).minimize(cross_entropy)\n",
    "\n",
    "with tf.name_scope('Accuracy'):\n",
    "    # Accuracy\n",
    "    correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    \n",
    "# create a summary for our cost and accuracy\n",
    "tf.scalar_summary(\"cost\", cross_entropy)\n",
    "tf.scalar_summary(\"accuracy\", accuracy)\n",
    "\n",
    "# merge all summaries into a single \"operation\" which we can execute in a session \n",
    "summary_op = tf.merge_all_summaries()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # variables need to be initialized before we can use them\n",
    "    sess.run(tf.initialize_all_variables())\n",
    "\n",
    "    # create log writer object\n",
    "    writer = tf.train.SummaryWriter(\"./logs/NN\", graph=tf.get_default_graph())\n",
    "        \n",
    "    # perform training cycles\n",
    "    for epoch in range(training_epochs):\n",
    "        \n",
    "        # number of batches in one epoch\n",
    "        batch_count = int(mnist.train.num_examples/batch_size)\n",
    "        \n",
    "        for i in range(batch_count):\n",
    "            batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "            \n",
    "            # perform the operations we defined earlier on batch\n",
    "            _, summary = sess.run([train_op, summary_op], feed_dict={x: batch_x, y_: batch_y})\n",
    "            \n",
    "            # write log\n",
    "            writer.add_summary(summary, epoch * batch_count + i)\n",
    "            \n",
    "        if epoch % 5 == 0: \n",
    "            print \"Epoch: \", epoch \n",
    "    print \"Accuracy: \", accuracy.eval(feed_dict={x: mnist.test.images, y_: mnist.test.labels})\n",
    "    print \"done\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
