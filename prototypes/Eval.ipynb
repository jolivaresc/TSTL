{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.5.0-rc0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import utils\n",
    "import numpy as np\n",
    "\n",
    "__author__ = \"Olivares Castillo José Luis\"\n",
    "tf.__version__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "es,na = utils.load_node2vec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "129"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_es, index_na = utils.get_seed_index(es, na)\n",
    "es_vectores = utils.get_vectors(es, index_es)\n",
    "na_vectores = utils.get_vectors(na, index_na)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#index_es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexes=[es.iloc[_][0] for _ in index_es]\n",
    "lexna=[na.iloc[_][0] for _ in index_na]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_lexicon =list(zip(lexes,lexna))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for _ in new_lexicon:\n",
    "#    print(_[0],_[1])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "with open(\"newlexicon.lst\",\"w\") as fd:\n",
    "    for _ in new_lexicon:\n",
    "        fd.write(_[0]+\" \"+_[1]+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: 0, dtype: object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es[es[0] == \"y\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: 0, dtype: object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es[es[0] == \"se\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: 0, dtype: object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "na[na[0] == \"no\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1904, 128)\n"
     ]
    }
   ],
   "source": [
    "es_dummy = es.drop(es.columns[0],axis=1)\n",
    "na_dummy = na.drop(na.columns[0],axis=1)\n",
    "es_vectores1 = np.array(es_dummy)\n",
    "na_vectores1 = np.array(na_dummy)\n",
    "print(na_vectores1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#es_vectores = [es.iloc[_].loc[1::] for _ in range(es.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sal\n"
     ]
    }
   ],
   "source": [
    "print(es.iloc[3421][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(540, 128)\n"
     ]
    }
   ],
   "source": [
    "# Palabra y vector\n",
    "#indice = 1756\n",
    "#print(es.iloc[3508][0])\n",
    "test_vectors = np.array([np.array(es.iloc[indice][1::]).astype(np.float64) for indice in index_es])\n",
    "#test_vectors = na_vectores1\n",
    "#test_vectors = np.array(es.iloc[2537][1::]).astype(np.float64)\n",
    "#test_vectors.resize(1,128)\n",
    "print(test_vectors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelos\n",
    "\n",
    "## Test 1\n",
    "\n",
    "* `LEARNING_RATE = 0.4666`\n",
    "* `NODES_H1 = 300`\n",
    "* `XAVIER_INIT = False`\n",
    "* `EPOCHS = 370000`\n",
    "* `fc1 = activation_function(fc1, \"relu\", \"fc1\")`\n",
    "* `nah_predicted = activation_function(output, \"sigmoid\", \"output\")`\n",
    "* Loss Function = MSE\n",
    "* `optimiser = tf.train.AdagradOptimizer(learning_rate=LEARNING_RATE)` W/ gradient clipping."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "saver = tf.train.import_meta_graph('./models/model1/Adagrad_H_300_LR_0.4666.ckpt.meta')\n",
    "saver.restore(sess,tf.train.latest_checkpoint('./models/model1/'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 2\n",
    "\n",
    "* `LEARNING_RATE = 1.0` [Ver liga](https://stackoverflow.com/questions/43892849/keras-batchnorm-training-accuracy-increases-while-testing-accuracy-decreases)\n",
    "* `NODES_H1 = 90`\n",
    "* `XAVIER_INIT = True`\n",
    "* `EPOCHS = 370000`\n",
    "* `fc1 = activation_function(fc1, \"sigmoid\", \"fc1\")`\n",
    "* `nah_predicted = fully_connected_layer(fc1, NODES_H1, NODES_OUPUT, \"output\",xavier_init=XAVIER_INIT)`\n",
    "**NOTA:** No se activa la capa de salida.\n",
    "* Loss Function = MSE\n",
    "* `optimiser = tf.train.MomentumOptimizer(learning_rate=LEARNING_RATE,momentum=0.5)` W/ gradient clipping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./models/model2/Momentum_H_90_LR_1.0.ckpt\n"
     ]
    }
   ],
   "source": [
    "saver = tf.train.import_meta_graph('./models/model2/Momentum_H_90_LR_1.0.ckpt.meta')\n",
    "saver.restore(sess,tf.train.latest_checkpoint('./models/model2/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = tf.get_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(sess.run(\"output/W:0\"))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "output_W = graph.get_tensor_by_name(\"output/W:0\")\n",
    "output_b = graph.get_tensor_by_name(\"output/b:0\")\n",
    "output_xwb = graph.get_tensor_by_name(\"output/xw_plus_b:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = graph.get_tensor_by_name(\"input/input_es:0\")\n",
    "#y = graph.get_tensor_by_name(\"input/target_na:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 128)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "feed_dict = {X:test_vectors}"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Salida modelo 1\n",
    "output_NN = graph.get_tensor_by_name(\"output_1:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Salida modelo 2\n",
    "output_NN = graph.get_tensor_by_name(\"output/xw_plus_b:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> (540, 128)\n"
     ]
    }
   ],
   "source": [
    "pred = sess.run(output_NN,feed_dict)\n",
    "print (type(pred[0]),pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(pred[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10=[utils.get_top10_closest(pred[_],na_vectores1) for _ in range(pred.shape[0])]\n",
    "#top_10=utils.get_top10_closest(pred[0],na_vectores1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "closest = [utils.get_closest_words_to(top_10[_],na) for _ in range(pred.shape[0])]\n",
    "#closest = utils.get_closest_words_to(top_10,na)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['izta',\n",
       " 'ixquich',\n",
       " 'rosario',\n",
       " 'dral',\n",
       " 'secretario',\n",
       " 'federal',\n",
       " 'diego',\n",
       " 'castillo',\n",
       " 'acamapich',\n",
       " 'echicoliz']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "closest[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#acc1=[(_,lexna[_] == closest[_][0]) for _ in range(pred.shape[0])]\n",
    "acc=[(lexna[_] == closest[_][0]) for _ in range(pred.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_list = np.array(acc).astype(np.int)\n",
    "precision_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = Counter(precision_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 24, 1: 516})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión con lexicon de entrenamiento: 95.55555555555556\n"
     ]
    }
   ],
   "source": [
    "print(\"Precisión con lexicon de entrenamiento:\",(precision[1]/len(precision_list))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
